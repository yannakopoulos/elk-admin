input {
    file {
        path => "/tmpscratch/users/matze/ttH/v29/**/report.json"
        start_position => beginning
        ignore_older => 0
	    close_older => 1
        type => "logs"

    	# this makes logstash read files even if it already has a record of
    	# reading them - good for testing, but delete when monitoring for real
    	sincedb_path => "/dev/null"

    	codec => multiline {
            pattern => "."
    	    what => "previous"
            max_lines => 1000000
    	    auto_flush_interval => 1
        }

    }
}

filter {

    if [path] =~ /.+/ {
       ruby {
          code => 'require "open3"
                   file_path = event["path"]
                   cmd =  "python /afs/crc.nd.edu/user/a/ayannako/scripts/filter_report_json.py -f #{file_path}"
                   stdin, stdout, stderr = Open3.popen3(cmd)
                   event["process_result"] = stdout.read
                   err = stderr.read
                   if err.to_s.empty?
                     filter_matched(event)
                   else
                     event["ext_script_err_msg"] = err
                   end'
       }
    }

    # Parsing of the process_result is here (see the next section)
    if [process_result] =~ /.+/ {
        json {
            source => "process_result"
            remove_field => [ "process_result" ]
        }
    }

    mutate {
        remove_field => ["message", "path", "host", "[report_json][is_good_doc]"]
    }

    # parse additional timestamps
    date {
        match => ["[report_json][task timing][epilogue end]", "UNIX"]
        target => "[report_json][task timing][epilogue end]"
    }

    date {
        match => ["[report_json][task timing][processing end]", "UNIX"]
        target => "[report_json][task timing][processing end]"
    }

    date {
        match => ["[report_json][task timing][prologue end]", "UNIX"]
        target => "[report_json][task timing][prologue end]"
    }

    date {
        match => ["[report_json][task timing][stage in end]", "UNIX"]
        target => "[report_json][task timing][stage in end]"
    }

    date {
        match => ["[report_json][task timing][stage out end]", "UNIX" ]
        target => "[report_json][task timing][stage out end]"
    }

    date {
        match => ["[report_json][task timing][wrapper end]", "UNIX"]
        target => "[report_json][task timing][wrapper end]"
    }

    date {
        match => ["[report_json][task timing][wrapper ready]", "UNIX"]
        target => "[report_json][task timing][wrapper ready]"
    }

    date {
        match => ["[report_json][task timing][wrapper start]", "UNIX"]
        target => "[report_json][task timing][wrapper start]"
    }


}

output {
    elasticsearch {
        index => "[template]_lobster_tasks"
        action => "update"
        document_id => "%{[report_json][id]}"
        doc_as_upsert => true
    }

    # remove to not be swamped with confirmation messages in terminal
    stdout { }

}
