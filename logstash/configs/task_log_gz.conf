input {
    file {
        path => "/tmpscratch/users/matze/ttH/v29/**/task.log.gz"
	    # path => "/afs/crc.nd.edu/user/a/ayannako/data/task.log.gz"
        start_position => beginning
        ignore_older => 0
        close_older => 1
        # type => "logs"

    	# this makes logstash read files even if it already has a record of
    	# reading them - good for testing, but delete when monitoring for real
    	sincedb_path => "/dev/null"

	    codec => multiline {
            pattern => "."
            what => "previous"
            max_lines => 1000000
            auto_flush_interval => 1
        }

    }
}

filter {
    # Launching external script to make a deeper text analysis
    if [path] =~ /.+/ {
       ruby {
          code => 'require "open3"
                   file_path = event["path"]
                   cmd =  "python /afs/crc.nd.edu/user/a/ayannako/scripts/filter_task_log_gz.py -f #{file_path}"
                   stdin, stdout, stderr = Open3.popen3(cmd)
                   event["process_result"] = stdout.read
                   err = stderr.read
                   if err.to_s.empty?
                     filter_matched(event)
                   else
                     event["ext_script_err_msg"] = err
                   end'
       }
    }

    # Parsing of the process_result is here (see the next section)
    if [process_result] =~ /.+/ {
        json {
            source => "process_result"
            remove_field => [ "process_result" ]
        }
    }

    mutate {
        remove_field => ["message", "path", "host", "[task_log_gz][is_good_doc]"]
    }

}


output {
    elasticsearch {
        index => "[template]_lobster_tasks"
        action => "update"
        document_id => "%{[task_log_gz][id]}"
        doc_as_upsert => true
    }

    # remove to not be swamped with confirmation messages in terminal
    stdout { }

}
